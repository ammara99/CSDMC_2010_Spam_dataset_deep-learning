{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "sys.path.append(path.abspath('./util'))\n",
    "#from clearMail import Mail2txt\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from spacy import displacy\n",
    "import spacy\n",
    "from sklearn.metrics import classification_report \n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "#from textblob import TextBlob\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import seaborn as sns\n",
    "from math import sqrt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score,cohen_kappa_score,f1_score,recall_score,precision_score,accuracy_score\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras.layers import LSTM, GRU, Embedding, Dense\n",
    "from tensorflow.python.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.python.keras.activations import sigmoid, softmax, tanh\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, MultiLabelBinarizer\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "#from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, LSTM, Embedding, GRU\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from tensorflow.python.keras.datasets import imdb\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import LSTM,Bidirectional\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session =tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_list = []\n",
    "for root, dirs, files in os.walk('ham/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                text = f.read()\n",
    "                ham_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_list = []\n",
    "for root, dirs, files in os.walk('spam/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(root, file), 'r') as f:\n",
    "                text = f.read()\n",
    "                spam_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ham_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham = pd.DataFrame()\n",
    "df_spam = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham['Ham']= ham_list\n",
    "df_spam['spam']= spam_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ham preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = []\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(len(df_ham['Ham'])):\n",
    "       # Remove all the special characters\n",
    "        document = re.sub(r'\\W', ' ', str(df_ham.iloc[sen]))\n",
    "\n",
    "        # remove all punctuations\n",
    "        document = re.sub(re.escape(string.punctuation), '', document)\n",
    "\n",
    "        # remove all single characters\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "\n",
    "        # Lemmatization\n",
    "        document = document.split()\n",
    "\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "\n",
    "        document = [ word for word in document.split() if word not in stopwords.words(\"english\")]\n",
    "        document = ' '.join(document)\n",
    "\n",
    "        documents.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham['Clean_text']= documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(len(df_spam['spam'])):\n",
    "       # Remove all the special characters\n",
    "        document = re.sub(r'\\W', ' ', str(df_spam.iloc[sen]))\n",
    "\n",
    "        # remove all punctuations\n",
    "        document = re.sub(re.escape(string.punctuation), '', document)\n",
    "\n",
    "        # remove all single characters\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "\n",
    "        # Lemmatization\n",
    "        document = document.split()\n",
    "\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "\n",
    "        document = [ word for word in document.split() if word not in stopwords.words(\"english\")]\n",
    "        document = ' '.join(document)\n",
    "\n",
    "        documents.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam['Clean_text']= documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham['label']= df_ham['Clean_text'].apply(lambda x : x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham['Clean_text']= df_ham['Clean_text'].apply(lambda x : \" \".join(x.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham['polarity']= df_ham['Clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham['subjectivity']= df_ham['Clean_text'].apply(lambda x: TextBlob(x).sentiment.subjectivity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam['label']= df_spam['Clean_text'].apply(lambda x : x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam['Clean_text']= df_spam['Clean_text'].apply(lambda x : \" \".join(x.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam['polarity']= df_spam['Clean_text'].apply(lambda x: round(float(TextBlob(x).sentiment.polarity), 4)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam['subjectivity']= df_spam['Clean_text'].apply(lambda x: round(float(TextBlob(x).sentiment.polarity), 4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df_ham[['Clean_text' ,'label' ,'polarity' ,'subjectivity']]\n",
    "df2= df_spam[['Clean_text' ,'label' ,'polarity' ,'subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SH = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_SH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SH['label']= df_SH['label'].map({'ham': 0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_SH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SH['Clean_text'].apply(lambda x: str(x)+\" -> \"+str(analyzer.polarity_scores(x)))[2952]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SH[df_SH['label']==0]['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SH[df_SH['label']==1]['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = pd.read_excel('Feature_extract.xlsx', sheet_name = 'feature', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_feature[['Length-of-Email', 'URLs-in-a-Email',\n",
    "       'Repititive-Words-in-a-Email', 'Uinque-Words-in-a-Email',\n",
    "       'Quoted-text-in-a-Email', 'Question-Marks-in-a-Email',\n",
    "       'Number of co-occuring words', 'Number of capitalized words',\n",
    "       'Number-of-noun', 'semantic', 'Neg-Sentiment', 'Neu-Sentiment',\n",
    "       'Pos-Sentiment', 'Comp-Sentiment', 'Spam lexicon', 'User features', 'Polarity', 'Subjective']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df_feature.iloc[:,1:-1] \n",
    "Y=df_feature['class'].values\n",
    "cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(X, Y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(Y)\n",
    "print(counter)\n",
    "labl= Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss= StandardScaler()\n",
    "X= ss.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "Y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(150, input_dim=16, activation='relu', kernel_regularizer=regularizers.l2(0.0012)))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(120, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "#model.add(Dense(110, activation='relu'))\n",
    "#model.add(Dropout(0.12))\n",
    "\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "#model.add(Dense(50, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x=X_train,y=Y_train,validation_split=0.20,batch_size=25,epochs=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'],marker='+')\n",
    "plt.plot(history.history['val_acc'],color='cyan',marker='*')\n",
    "# plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'],marker='+')\n",
    "plt.plot(history.history['val_loss'],color='cyan',marker='*')\n",
    "# plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print(\"Train Accuracy is\",train_acc)\n",
    "print(\"Test Accuracy is\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict crisp classes for test set\n",
    "yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "print(yhat_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.array(X_train)\n",
    "X_test= np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtraining_data= X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "\n",
    "Xtesting_data=X_test.reshape(X_test.shape[0],X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtraining_data[0].shape)\n",
    "print(Xtesting_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtraining_data.shape)\n",
    "print(Xtesting_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model with Highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu', input_shape=(18,1), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv1D(filters=120, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=100, kernel_size=4, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=3,padding='same'))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(Xtraining_data,Y_train,batch_size=6,epochs=75,\n",
    "          validation_data=(Xtesting_data,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,6))\n",
    "ax1.grid(False)\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['val_accuracy'])\n",
    "ax1.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
    "\n",
    "\n",
    "ax2.grid(False)\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.legend(['Training loss', 'Validation loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(Xtraining_data, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(Xtesting_data, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(Xtraining_data, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(Xtesting_data, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, labl, train_size=0.80, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(Xtesting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,model.predict_classes(Xtesting_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu', input_shape=(16,1), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv1D(filters=120, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=100, kernel_size=4, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(Xtraining_data,Y_train,batch_size=19,epochs=17,\n",
    "          validation_data=(Xtesting_data,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(False)\n",
    "plt.plot(history.history['acc'],marker='+')\n",
    "plt.plot(history.history['val_acc'],color='cyan',marker='*')\n",
    "# plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(False)\n",
    "plt.plot(history.history['loss'],marker='+')\n",
    "plt.plot(history.history['val_loss'],color='cyan',marker='*')\n",
    "# plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(Xtraining_data, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(Xtesting_data, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, labl, train_size=0.80, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(Xtesting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,model.predict_classes(Xtesting_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(Y_test,model.predict_classes(Xtesting_data)),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN GRU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu', input_shape=(16,1), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv1D(filters=120, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Conv1D(filters=100, kernel_size=4, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "#model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(GRU(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(Xtraining_data,Y_train,batch_size=19,epochs=18,\n",
    "          validation_data=(Xtesting_data,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(False)\n",
    "plt.plot(history.history['acc'],marker='+')\n",
    "plt.plot(history.history['val_acc'],color='cyan',marker='*')\n",
    "# plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(False)\n",
    "plt.plot(history.history['loss'],marker='+')\n",
    "plt.plot(history.history['val_loss'],color='cyan',marker='*')\n",
    "# plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(Xtraining_data, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(Xtesting_data, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, labl, train_size=0.80, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(Xtesting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,model.predict_classes(Xtesting_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(Y_test,model.predict_classes(Xtesting_data)),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
